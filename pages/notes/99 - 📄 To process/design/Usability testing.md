---
resources:
  - https://www.lyssna.com/guides/usability-testing-guide/
---
- great [guide](https://www.lyssna.com/guides/usability-testing-guide/) by Lyssna
- can use methods like [design surveys](https://www.lyssna.com/guides/design-surveys/), [5 second tests](https://www.lyssna.com/guides/five-second-testing/) or [concept testing](https://www.lyssna.com/blog/concept-testing/)
- ideally happens in a setting of one partcipant, one facilitator and one note-taker
- can be moderated on unmoderated
- it can be either [formative](https://www.lyssna.com/blog/formative-usability-testing/) or [summative](https://www.lyssna.com/blog/summative-usability-testing/)
	- formative is done sooner, summative earlier (usually to compare against each other) – comparison [here](https://www.lyssna.com/blog/formative-vs-summative-usability-testing/)
## Briefing participants
- - **Start with an overview:** Begin by providing an overview of the testing process, including the goals of the study, the tasks you’re asking participants to perform, and the type of feedback or data you’re looking to gather.
    
- **Explain the testing process:** Provide a step-by-step explanation of how the testing session will be conducted, including any equipment or tools participants will be using, and the order they’ll complete the tasks.
    
- **Clarify expectations:** Clearly explain what’s expected from participants, including how they should approach the tasks and anything specific they should keep in mind while testing, like explaining their thought process out loud.
    
- **Address questions and concerns:** Allow participants to ask questions and address any concerns they may have about the testing process.
## Note taking
- ideally use multiple senses (hear, observe, ...)
- ideally record a session and make notes together
- note taking can be pre-structured
	- e.g. predefine some categories I then just tick when asking for an answer
		- category for feedback, task completion, navigation smoothness, ...
		- Likert scales can help here
- *do not forget to record positive feedback*
- use descriptive language to capture the essence of the experience
- record
	- observations
	- quotes
	- actions they are taking
	- identified usability issues
	- questions that are arising
## Facilitation
- use probing questions like why, how or 'tell me more about ...' to get more in depth
- think-aloud protocol
- we're testing the tool, not you
## Test scenario
- a set of conditions or situations that a user would encounter while using your product
- tasks are specific actions that you ask a participant to perform during the usability testing session, they are representative of the typical activities that a user would perform while using your product
	- can be either exploratory (don't have a right or wrong answer) or specific (usually have a right or wrong answer)
- the scenario **should be realistic**